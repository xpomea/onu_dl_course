{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name: str, **kwargs):\n",
    "    activations = {\n",
    "        'relu': nn.ReLU,\n",
    "        'tanh': nn.Tanh,\n",
    "        'sigmoid': nn.Sigmoid,\n",
    "        'silu': nn.SiLU,\n",
    "        'softplus': nn.Softplus,\n",
    "        'leakyrelu': nn.LeakyReLU\n",
    "    }\n",
    "    if name in activations.keys():\n",
    "        return activations[name.lower()](**kwargs)\n",
    "    else:\n",
    "        raise KeyError('No such activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 5, 5])\n",
      "torch.Size([1, 4, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, type: str, in_channels: int, out_channels: Optional[int] = None, mid_channels: Optional[int] = None, activations: List[str] | str = 'relu', kernel_size: int = 3, stride: int = 1, padding: int = 1) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        n_layers = 2\n",
    "        \n",
    "        if not isinstance(activations, List):\n",
    "            activations = [activations] * n_layers\n",
    "        if len(activations) != n_layers:\n",
    "            raise Exception('Not enough activations')\n",
    "        \n",
    "        match type:\n",
    "            case 'Standard':\n",
    "                mid_channels = mid_channels or in_channels\n",
    "                out_channels = out_channels or in_channels\n",
    "                \n",
    "                self.layers = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, mid_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "                    nn.BatchNorm2d(mid_channels),\n",
    "                    get_activation(activations[0]),\n",
    "                    \n",
    "                    nn.Conv2d(mid_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "                    nn.BatchNorm2d(out_channels)\n",
    "                )\n",
    "            case 'Bottleneck':\n",
    "                mid_channels = mid_channels or in_channels // 2\n",
    "                out_channels = out_channels or in_channels\n",
    "                \n",
    "                self.layers = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, mid_channels, kernel_size=1),\n",
    "                    nn.BatchNorm2d(mid_channels),\n",
    "                    get_activation(activations[0]),\n",
    "                    \n",
    "                    nn.Conv2d(mid_channels, mid_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "                    nn.BatchNorm2d(mid_channels),\n",
    "                    get_activation(activations[1]),\n",
    "                    \n",
    "                    nn.Conv2d(mid_channels, out_channels, kernel_size=1),\n",
    "                    nn.BatchNorm2d(out_channels)\n",
    "                )\n",
    "            case _:\n",
    "                raise Exception('Unsupported block type')\n",
    "                \n",
    "        self.activation = get_activation(activations[-1])\n",
    "        \n",
    "        self.sc_pool = None\n",
    "        self.sc_scale = None\n",
    "        \n",
    "        if stride > 1:\n",
    "            self.sc_pool = nn.AvgPool2d(kernel_size=stride, stride=stride)\n",
    "        if in_channels != out_channels:\n",
    "            self.sc_scale = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        \n",
    "        x = self.layers(x)\n",
    "                \n",
    "        if self.sc_pool:\n",
    "            shortcut = self.sc_pool(shortcut)\n",
    "        if self.sc_scale:\n",
    "            shortcut = self.sc_scale(shortcut)\n",
    "        \n",
    "        x = self.activation(shortcut + x)\n",
    "        return x\n",
    "print(ResidualBlock('Standard', 2, 4, stride=2)(torch.rand(1, 2, 10, 10)).shape)\n",
    "print(ResidualBlock('Bottleneck', 2, 4, stride=2)(torch.rand(1, 2, 10, 10)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
